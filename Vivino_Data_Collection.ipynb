{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE: RAN THIS SUCCESSFULLY FOR PAGE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def init_driver():\n",
    "    print(\"Initializing the Chrome driver...\")\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page_and_agree(driver, base_url):\n",
    "    print(f\"Navigating to {base_url}...\")\n",
    "    driver.get(base_url)\n",
    "    time.sleep(10)  # Increase the wait time if needed\n",
    "\n",
    "    try:\n",
    "        print(\"Looking for the 'Agree and Close' button...\")\n",
    "        agree_button = driver.find_element(By.XPATH, '//*[@id=\"didomi-notice-agree-button\"]/span')\n",
    "        agree_button.click()\n",
    "        print(\"'Agree and Close' button clicked.\")\n",
    "        time.sleep(10)  # Increase the wait time if needed\n",
    "    except Exception as e:\n",
    "        print(\"No 'Agree and Close' button found or error in clicking:\", e)\n",
    "\n",
    "def scrape_reviews(driver, star_xpath, max_reviews=200):\n",
    "    try:\n",
    "        print(f\"Clicking on the star rating with XPath: {star_xpath}...\")\n",
    "        star_button = driver.find_element(By.XPATH, star_xpath)\n",
    "        star_button.click()\n",
    "        time.sleep(10)  # Increase the wait time if needed\n",
    "\n",
    "        reviews = []\n",
    "        unique_commenters = set()\n",
    "        scrollable_popup = driver.find_element(By.XPATH, '//*[@id=\"baseModal\"]/div/div[2]')\n",
    "\n",
    "        last_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_popup)\n",
    "        while len(reviews) < max_reviews:\n",
    "            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollable_popup)\n",
    "            time.sleep(5)  # Increase the wait time if needed\n",
    "\n",
    "            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_popup)\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "            review_elements = driver.find_elements(By.XPATH, '//*[@id=\"baseModal\"]/div/div[2]/div[3]/div')\n",
    "            print(f\"Found {len(review_elements)} review elements\")\n",
    "            for review_element in review_elements:\n",
    "                if len(reviews) >= max_reviews:\n",
    "                    break\n",
    "                try:\n",
    "                    rating = review_element.find_element(By.XPATH, 'div/div[1]/div[1]/a/span[1]').text.strip()\n",
    "\n",
    "                    spans = review_element.find_elements(By.XPATH, 'div/div[1]/div[1]/a/span')\n",
    "                    if len(spans) == 3:\n",
    "                        review_text = spans[2].text.strip()\n",
    "                    else:\n",
    "                        review_text = spans[1].text.strip()\n",
    "\n",
    "                    commenter_name = review_element.find_element(By.XPATH, 'div/div[1]/div[2]/div[1]/div/a[1]').text.strip()\n",
    "                    review_date = review_element.find_element(By.XPATH, 'div/div[1]/div[2]/div[1]/div/a[2]').text.strip()\n",
    "\n",
    "                    if commenter_name not in unique_commenters:\n",
    "                        reviews.append({\n",
    "                            'Rating': rating,\n",
    "                            'Review Text': review_text,\n",
    "                            'Commenter Name': commenter_name,\n",
    "                            'Review Date': review_date\n",
    "                        })\n",
    "                        unique_commenters.add(commenter_name)\n",
    "                except Exception as e:\n",
    "                    print(\"Error in extracting review details:\", e)\n",
    "\n",
    "        print(f\"{len(reviews)} reviews scraped for {star_xpath.split()[-1]}-star rating.\")\n",
    "\n",
    "        # Unclick the star rating\n",
    "        star_button.click()\n",
    "        time.sleep(3)  # Wait for the action to be processed\n",
    "\n",
    "        return reviews\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error in scraping reviews for star rating:\", e)\n",
    "        return []\n",
    "\n",
    "def scrape_wine_reviews(driver, wine_url, wine_name):\n",
    "    driver.get(wine_url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    print(f\"Scraping reviews for {wine_name}\")\n",
    "\n",
    "    try:\n",
    "        average_rating_link = driver.find_element(By.XPATH, '//*[@id=\"wine-location-header\"]/div/div/div/div[2]/a')\n",
    "        average_rating_link.click()\n",
    "        time.sleep(10)\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight * 0.7);\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        show_more_reviews_button = driver.find_element(By.XPATH, '//*[@id=\"all_reviews\"]/div[2]/div[1]/button/span')\n",
    "        show_more_reviews_button.click()\n",
    "        time.sleep(10)\n",
    "\n",
    "        star_xpaths = {\n",
    "            '5': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]',\n",
    "            '4': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]',\n",
    "            '3': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]',\n",
    "            '2': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]',\n",
    "            '1': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]'\n",
    "        }\n",
    "\n",
    "        all_reviews = []\n",
    "        for star, xpath in star_xpaths.items():\n",
    "            print(f\"Scraping {star}-star reviews...\")\n",
    "            reviews = scrape_reviews(driver, xpath)\n",
    "            all_reviews.extend(reviews)\n",
    "\n",
    "        print(f\"Total reviews scraped: {len(all_reviews)}\")\n",
    "\n",
    "        return all_reviews\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in scraping reviews for {wine_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_banfi_wines(driver, base_url):\n",
    "    all_wine_details = []\n",
    "    all_reviews = []\n",
    "    scraped_wines = set()\n",
    "    driver.get(base_url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    try:\n",
    "        agree_button = driver.find_element(By.XPATH, '//*[@id=\"didomi-notice-agree-button\"]')\n",
    "        agree_button.click()\n",
    "        time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(\"No 'Agree and Continue' button found or error in clicking:\", e)\n",
    "\n",
    "    print(\"Scraping wines on the current page\")\n",
    "\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(10)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    wines = soup.find_all('div', class_='card card-lg')\n",
    "\n",
    "    for wine in wines:\n",
    "        try:\n",
    "            wine_name = wine.find('a', class_='link-color-alt-grey').text.strip()\n",
    "            if \"Banfi\" in wine_name and wine_name not in scraped_wines:\n",
    "                wine_link = wine.find('a', class_='link-color-alt-grey')['href']\n",
    "                wine_url = f\"https://www.vivino.com{wine_link}\"\n",
    "                print(f\"Scraping reviews for {wine_name}\")\n",
    "\n",
    "                wine_details = {\n",
    "                    'Wine Name': wine_name,\n",
    "                    'Brand': 'Banfi',\n",
    "                    'Country': 'Italy'\n",
    "                }\n",
    "\n",
    "                driver.get(wine_url)\n",
    "                time.sleep(10)\n",
    "                soup_wine = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                try:\n",
    "                    wine_price = soup_wine.find('span', class_='wine-price-value').text.strip()\n",
    "                    wine_details['Price'] = wine_price\n",
    "                except Exception as e:\n",
    "                    print(\"Error in extracting price:\", e)\n",
    "\n",
    "                wine_reviews = scrape_wine_reviews(driver, wine_url, wine_name)\n",
    "                all_reviews.extend(wine_reviews)\n",
    "                all_wine_details.append(wine_details)\n",
    "                scraped_wines.add(wine_name)\n",
    "\n",
    "                driver.get(base_url)\n",
    "                time.sleep(10)\n",
    "        except Exception as e:\n",
    "            print(\"Error in processing wine:\", e)\n",
    "\n",
    "    # Check if there is a next page\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '/html/body/div[3]/section[1]/div/div/div/div[2]/button[2]')\n",
    "        print(\"Next page button found, terminating the script.\")\n",
    "    except Exception as e:\n",
    "        print(\"No more pages to load or error in finding next button:\", e)\n",
    "\n",
    "    return all_wine_details, all_reviews\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        driver = init_driver()\n",
    "        base_url = \"https://www.vivino.com/search/wines?q=banfi+\"\n",
    "        all_wine_details, all_reviews = scrape_all_banfi_wines(driver, base_url)\n",
    "        \n",
    "        df_wine_details = pd.DataFrame(all_wine_details)\n",
    "        df_reviews = pd.DataFrame(all_reviews)\n",
    "\n",
    "        df_wine_details.to_csv('banfi_wine_details.csv', index=False)\n",
    "        df_reviews.to_csv('banfi_wine_reviews.csv', index=False)\n",
    "\n",
    "        df_wine_details.to_json('banfi_wine_details.json', orient='records', lines=True)\n",
    "        df_reviews.to_json('banfi_wine_reviews.json', orient='records', lines=True)\n",
    "\n",
    "        print(\"DataFrames saved as CSV and JSON files.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Process interrupted. Saving files...\")\n",
    "\n",
    "        df_wine_details.to_csv('banfi_wine_details.csv', index=False)\n",
    "        df_reviews.to_csv('banfi_wine_reviews.csv', index=False)\n",
    "\n",
    "        df_wine_details.to_json('banfi_wine_details.json', orient='records', lines=True)\n",
    "        df_reviews.to_json('banfi_wine_reviews.json', orient='records', lines=True)\n",
    "\n",
    "        print(\"DataFrames saved as CSV and JSON files.\")\n",
    "        driver.quit()\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def init_driver():\n",
    "    print(\"Initializing the Chrome driver...\")\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page_and_agree(driver, base_url):\n",
    "    print(f\"Navigating to {base_url}...\")\n",
    "    driver.get(base_url)\n",
    "    time.sleep(10)  # Increase the wait time if needed\n",
    "\n",
    "    try:\n",
    "        print(\"Looking for the 'Agree and Close' button...\")\n",
    "        agree_button = driver.find_element(By.XPATH, '//*[@id=\"didomi-notice-agree-button\"]/span')\n",
    "        agree_button.click()\n",
    "        print(\"'Agree and Close' button clicked.\")\n",
    "        time.sleep(10)  # Increase the wait time if needed\n",
    "    except Exception as e:\n",
    "        print(\"No 'Agree and Close' button found or error in clicking:\", e)\n",
    "\n",
    "def scrape_reviews(driver, star_xpath, max_reviews=200):\n",
    "    try:\n",
    "        print(f\"Clicking on the star rating with XPath: {star_xpath}...\")\n",
    "        star_button = driver.find_element(By.XPATH, star_xpath)\n",
    "        star_button.click()\n",
    "        time.sleep(10)  # Increase the wait time if needed\n",
    "\n",
    "        reviews = []\n",
    "        unique_commenters = set()\n",
    "        scrollable_popup = driver.find_element(By.XPATH, '//*[@id=\"baseModal\"]/div/div[2]')\n",
    "\n",
    "        last_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_popup)\n",
    "        while len(reviews) < max_reviews:\n",
    "            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollable_popup)\n",
    "            time.sleep(5)  # Increase the wait time if needed\n",
    "\n",
    "            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_popup)\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "            review_elements = driver.find_elements(By.XPATH, '//*[@id=\"baseModal\"]/div/div[2]/div[3]/div')\n",
    "            print(f\"Found {len(review_elements)} review elements\")\n",
    "            for review_element in review_elements:\n",
    "                if len(reviews) >= max_reviews:\n",
    "                    break\n",
    "                try:\n",
    "                    rating = review_element.find_element(By.XPATH, 'div/div[1]/div[1]/a/span[1]').text.strip()\n",
    "\n",
    "                    spans = review_element.find_elements(By.XPATH, 'div/div[1]/div[1]/a/span')\n",
    "                    if len(spans) == 3:\n",
    "                        review_text = spans[2].text.strip()\n",
    "                    else:\n",
    "                        review_text = spans[1].text.strip()\n",
    "\n",
    "                    commenter_name = review_element.find_element(By.XPATH, 'div/div[1]/div[2]/div[1]/div/a[1]').text.strip()\n",
    "                    review_date = review_element.find_element(By.XPATH, 'div/div[1]/div[2]/div[1]/div/a[2]').text.strip()\n",
    "\n",
    "                    if commenter_name not in unique_commenters:\n",
    "                        reviews.append({\n",
    "                            'Rating': rating,\n",
    "                            'Review Text': review_text,\n",
    "                            'Commenter Name': commenter_name,\n",
    "                            'Review Date': review_date\n",
    "                        })\n",
    "                        unique_commenters.add(commenter_name)\n",
    "                except Exception as e:\n",
    "                    print(\"Error in extracting review details:\", e)\n",
    "\n",
    "        print(f\"{len(reviews)} reviews scraped for {star_xpath.split()[-1]}-star rating.\")\n",
    "\n",
    "        # Unclick the star rating\n",
    "        star_button.click()\n",
    "        time.sleep(3)  # Wait for the action to be processed\n",
    "\n",
    "        return reviews\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error in scraping reviews for star rating:\", e)\n",
    "        return []\n",
    "\n",
    "def scrape_wine_reviews(driver, wine_url, wine_name):\n",
    "    driver.get(wine_url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    print(f\"Scraping reviews for {wine_name}\")\n",
    "\n",
    "    try:\n",
    "        average_rating_link = driver.find_element(By.XPATH, '//*[@id=\"wine-location-header\"]/div/div/div/div[2]/a')\n",
    "        average_rating_link.click()\n",
    "        time.sleep(10)\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight * 0.7);\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        show_more_reviews_button = driver.find_element(By.XPATH, '//*[@id=\"all_reviews\"]/div[2]/div[1]/button/span')\n",
    "        show_more_reviews_button.click()\n",
    "        time.sleep(10)\n",
    "\n",
    "        star_xpaths = {\n",
    "            '5': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]',\n",
    "            '4': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]',\n",
    "            '3': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]',\n",
    "            '2': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]',\n",
    "            '1': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]'\n",
    "        }\n",
    "\n",
    "        all_reviews = []\n",
    "        for star, xpath in star_xpaths.items():\n",
    "            print(f\"Scraping {star}-star reviews...\")\n",
    "            reviews = scrape_reviews(driver, xpath)\n",
    "            all_reviews.extend(reviews)\n",
    "\n",
    "        print(f\"Total reviews scraped: {len(all_reviews)}\")\n",
    "\n",
    "        return all_reviews\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in scraping reviews for {wine_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_banfi_wines(driver, base_url):\n",
    "    all_wine_details = []\n",
    "    all_reviews = []\n",
    "    scraped_wines = set()\n",
    "    driver.get(base_url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    try:\n",
    "        agree_button = driver.find_element(By.XPATH, '//*[@id=\"didomi-notice-agree-button\"]')\n",
    "        agree_button.click()\n",
    "        time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(\"No 'Agree and Continue' button found or error in clicking:\", e)\n",
    "\n",
    "    print(\"Scraping wines on the current page\")\n",
    "\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(10)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    wines = soup.find_all('div', class_='card card-lg')\n",
    "\n",
    "    for wine in wines:\n",
    "        try:\n",
    "            wine_name = wine.find('a', class_='link-color-alt-grey').text.strip()\n",
    "            if \"Banfi\" in wine_name and wine_name not in scraped_wines:\n",
    "                wine_link = wine.find('a', class_='link-color-alt-grey')['href']\n",
    "                wine_url = f\"https://www.vivino.com{wine_link}\"\n",
    "                print(f\"Scraping reviews for {wine_name}\")\n",
    "\n",
    "                wine_details = {\n",
    "                    'Wine Name': wine_name,\n",
    "                    'Brand': 'Banfi',\n",
    "                    'Country': 'Italy'\n",
    "                }\n",
    "\n",
    "                driver.get(wine_url)\n",
    "                time.sleep(10)\n",
    "                soup_wine = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                try:\n",
    "                    wine_price = soup_wine.find('span', class_='wine-price-value').text.strip()\n",
    "                    wine_details['Price'] = wine_price\n",
    "                except Exception as e:\n",
    "                    print(\"Error in extracting price:\", e)\n",
    "\n",
    "                wine_reviews = scrape_wine_reviews(driver, wine_url, wine_name)\n",
    "                all_reviews.extend(wine_reviews)\n",
    "                all_wine_details.append(wine_details)\n",
    "                scraped_wines.add(wine_name)\n",
    "\n",
    "                driver.get(base_url)\n",
    "                time.sleep(10)\n",
    "        except Exception as e:\n",
    "            print(\"Error in processing wine:\", e)\n",
    "\n",
    "    # Check if there is a next page\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '/html/body/div[3]/section[1]/div/div/div/div[2]/button[2]')\n",
    "        print(\"Next page button found, terminating the script.\")\n",
    "    except Exception as e:\n",
    "        print(\"No more pages to load or error in finding next button:\", e)\n",
    "\n",
    "    return all_wine_details, all_reviews\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        driver = init_driver()\n",
    "        base_url = \"https://www.vivino.com/search/wines?q=banfi&start=2\"\n",
    "        all_wine_details, all_reviews = scrape_all_banfi_wines(driver, base_url)\n",
    "        \n",
    "        df_wine_details = pd.DataFrame(all_wine_details)\n",
    "        df_reviews = pd.DataFrame(all_reviews)\n",
    "\n",
    "        df_wine_details.to_csv('banfi_wine_details_page2.csv', index=False)\n",
    "        df_reviews.to_csv('banfi_wine_reviews_page2.csv', index=False)\n",
    "\n",
    "        df_wine_details.to_json('banfi_wine_details_page2.json', orient='records', lines=True)\n",
    "        df_reviews.to_json('banfi_wine_reviews.json_page2', orient='records', lines=True)\n",
    "\n",
    "        print(\"DataFrames saved as CSV and JSON files.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Process interrupted. Saving files...\")\n",
    "\n",
    "        df_wine_details.to_csv('banfi_wine_details_page2.csv', index=False)\n",
    "        df_reviews.to_csv('banfi_wine_reviews_page2.csv', index=False)\n",
    "\n",
    "        df_wine_details.to_json('banfi_wine_details_page2.json', orient='records', lines=True)\n",
    "        df_reviews.to_json('banfi_wine_reviews_page2.json', orient='records', lines=True)\n",
    "\n",
    "        print(\"DataFrames saved as CSV and JSON files.\")\n",
    "        driver.quit()\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/7fnvl7c15wjdqsd4zks4cz8w0000gn/T/ipykernel_78619/4246544961.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the Chrome driver...\n",
      "Scraping wines on the current page\n",
      "Scraping reviews for Banfi Tener Sauvignon - Chardonnay Extra Dry\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Tener Sauvignon - Chardonnay Extra Dry\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 20 review elements\n",
      "Found 22 review elements\n",
      "Found 22 review elements\n",
      "22 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 60 review elements\n",
      "Found 70 review elements\n",
      "Found 78 review elements\n",
      "Found 78 review elements\n",
      "78 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "1 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 121\n",
      "Scraping reviews for Banfi Le Rime Pinot Grigio\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Le Rime Pinot Grigio\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 20 review elements\n",
      "Found 25 review elements\n",
      "Found 25 review elements\n",
      "25 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 60 review elements\n",
      "Found 70 review elements\n",
      "Found 77 review elements\n",
      "Found 77 review elements\n",
      "77 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 39 review elements\n",
      "Found 39 review elements\n",
      "39 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 5 review elements\n",
      "5 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 156\n",
      "Scraping reviews for Banfi Rivo al Poggio Bianco\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Rivo al Poggio Bianco\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 3 review elements\n",
      "3 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 19 review elements\n",
      "Found 19 review elements\n",
      "19 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 47 review elements\n",
      "Found 47 review elements\n",
      "47 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 4 review elements\n",
      "4 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 83\n",
      "Scraping reviews for Banfi Florus Moscadello di Montalcino Late Harvest\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Florus Moscadello di Montalcino Late Harvest\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 60 review elements\n",
      "Found 70 review elements\n",
      "Found 74 review elements\n",
      "Found 74 review elements\n",
      "74 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 60 review elements\n",
      "Found 70 review elements\n",
      "Found 80 review elements\n",
      "Found 90 review elements\n",
      "Found 100 review elements\n",
      "Found 110 review elements\n",
      "Found 120 review elements\n",
      "Found 130 review elements\n",
      "Found 140 review elements\n",
      "Found 150 review elements\n",
      "Found 160 review elements\n",
      "Found 170 review elements\n",
      "Found 173 review elements\n",
      "Found 173 review elements\n",
      "173 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 3 review elements\n",
      "3 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "1 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 261\n",
      "Scraping reviews for Banfi Fonte Alla Selva Chianti Classico Gran Selezione\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Fonte Alla Selva Chianti Classico Gran Selezione\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 16 review elements\n",
      "Found 16 review elements\n",
      "16 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 60 review elements\n",
      "Found 70 review elements\n",
      "Found 80 review elements\n",
      "Found 90 review elements\n",
      "Found 100 review elements\n",
      "Found 102 review elements\n",
      "Found 102 review elements\n",
      "102 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 2 review elements\n",
      "2 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "Error in extracting review details: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"div/div[1]/div[1]/a/span[1]\"}\n",
      "  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001050b40e8 chromedriver + 5169384\n",
      "1   chromedriver                        0x00000001050abfba chromedriver + 5136314\n",
      "2   chromedriver                        0x0000000104c2836c chromedriver + 402284\n",
      "3   chromedriver                        0x0000000104c75740 chromedriver + 718656\n",
      "4   chromedriver                        0x0000000104c75a01 chromedriver + 719361\n",
      "5   chromedriver                        0x0000000104c69ff6 chromedriver + 671734\n",
      "6   chromedriver                        0x0000000104c98add chromedriver + 862941\n",
      "7   chromedriver                        0x0000000104c69ed8 chromedriver + 671448\n",
      "8   chromedriver                        0x0000000104c98c6e chromedriver + 863342\n",
      "9   chromedriver                        0x0000000104cb7f57 chromedriver + 991063\n",
      "10  chromedriver                        0x0000000104c98853 chromedriver + 862291\n",
      "11  chromedriver                        0x0000000104c685c6 chromedriver + 665030\n",
      "12  chromedriver                        0x0000000104c68e4e chromedriver + 667214\n",
      "13  chromedriver                        0x0000000105076d00 chromedriver + 4918528\n",
      "14  chromedriver                        0x000000010507bcfd chromedriver + 4939005\n",
      "15  chromedriver                        0x000000010507c3d5 chromedriver + 4940757\n",
      "16  chromedriver                        0x0000000105057de4 chromedriver + 4791780\n",
      "17  chromedriver                        0x000000010507c6c9 chromedriver + 4941513\n",
      "18  chromedriver                        0x00000001050495b4 chromedriver + 4732340\n",
      "19  chromedriver                        0x000000010509c898 chromedriver + 5073048\n",
      "20  chromedriver                        0x000000010509ca57 chromedriver + 5073495\n",
      "21  chromedriver                        0x00000001050abb6e chromedriver + 5135214\n",
      "22  libsystem_pthread.dylib             0x00007ff81961718b _pthread_start + 99\n",
      "23  libsystem_pthread.dylib             0x00007ff819612ae3 thread_start + 15\n",
      "\n",
      "0 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 130\n",
      "Scraping reviews for Banfi Centine Chardonnay - Vermentino\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Centine Chardonnay - Vermentino\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 18 review elements\n",
      "Found 18 review elements\n",
      "18 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 12 review elements\n",
      "Found 12 review elements\n",
      "12 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 51 review elements\n",
      "Found 51 review elements\n",
      "51 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 8 review elements\n",
      "8 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 3 review elements\n",
      "3 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 92\n",
      "Scraping reviews for Banfi Tener Spumante Brut\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Tener Spumante Brut\n",
      "Error in scraping reviews for Banfi Tener Spumante Brut: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"all_reviews\"]/div[2]/div[1]/button/span\"}\n",
      "  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001050b40e8 chromedriver + 5169384\n",
      "1   chromedriver                        0x00000001050abfba chromedriver + 5136314\n",
      "2   chromedriver                        0x0000000104c2836c chromedriver + 402284\n",
      "3   chromedriver                        0x0000000104c75740 chromedriver + 718656\n",
      "4   chromedriver                        0x0000000104c75a01 chromedriver + 719361\n",
      "5   chromedriver                        0x0000000104cbabc4 chromedriver + 1002436\n",
      "6   chromedriver                        0x0000000104c98add chromedriver + 862941\n",
      "7   chromedriver                        0x0000000104cb7f57 chromedriver + 991063\n",
      "8   chromedriver                        0x0000000104c98853 chromedriver + 862291\n",
      "9   chromedriver                        0x0000000104c685c6 chromedriver + 665030\n",
      "10  chromedriver                        0x0000000104c68e4e chromedriver + 667214\n",
      "11  chromedriver                        0x0000000105076d00 chromedriver + 4918528\n",
      "12  chromedriver                        0x000000010507bcfd chromedriver + 4939005\n",
      "13  chromedriver                        0x000000010507c3d5 chromedriver + 4940757\n",
      "14  chromedriver                        0x0000000105057de4 chromedriver + 4791780\n",
      "15  chromedriver                        0x000000010507c6c9 chromedriver + 4941513\n",
      "16  chromedriver                        0x00000001050495b4 chromedriver + 4732340\n",
      "17  chromedriver                        0x000000010509c898 chromedriver + 5073048\n",
      "18  chromedriver                        0x000000010509ca57 chromedriver + 5073495\n",
      "19  chromedriver                        0x00000001050abb6e chromedriver + 5135214\n",
      "20  libsystem_pthread.dylib             0x00007ff81961718b _pthread_start + 99\n",
      "21  libsystem_pthread.dylib             0x00007ff819612ae3 thread_start + 15\n",
      "\n",
      "Scraping reviews for Banfi Artigiano Rosso di Montalcino\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Artigiano Rosso di Montalcino\n",
      "Error in scraping reviews for Banfi Artigiano Rosso di Montalcino: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"all_reviews\"]/div[2]/div[1]/button/span\"}\n",
      "  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001050b40e8 chromedriver + 5169384\n",
      "1   chromedriver                        0x00000001050abfba chromedriver + 5136314\n",
      "2   chromedriver                        0x0000000104c2836c chromedriver + 402284\n",
      "3   chromedriver                        0x0000000104c75740 chromedriver + 718656\n",
      "4   chromedriver                        0x0000000104c75a01 chromedriver + 719361\n",
      "5   chromedriver                        0x0000000104cbabc4 chromedriver + 1002436\n",
      "6   chromedriver                        0x0000000104c98add chromedriver + 862941\n",
      "7   chromedriver                        0x0000000104cb7f57 chromedriver + 991063\n",
      "8   chromedriver                        0x0000000104c98853 chromedriver + 862291\n",
      "9   chromedriver                        0x0000000104c685c6 chromedriver + 665030\n",
      "10  chromedriver                        0x0000000104c68e4e chromedriver + 667214\n",
      "11  chromedriver                        0x0000000105076d00 chromedriver + 4918528\n",
      "12  chromedriver                        0x000000010507bcfd chromedriver + 4939005\n",
      "13  chromedriver                        0x000000010507c3d5 chromedriver + 4940757\n",
      "14  chromedriver                        0x0000000105057de4 chromedriver + 4791780\n",
      "15  chromedriver                        0x000000010507c6c9 chromedriver + 4941513\n",
      "16  chromedriver                        0x00000001050495b4 chromedriver + 4732340\n",
      "17  chromedriver                        0x000000010509c898 chromedriver + 5073048\n",
      "18  chromedriver                        0x000000010509ca57 chromedriver + 5073495\n",
      "19  chromedriver                        0x00000001050abb6e chromedriver + 5135214\n",
      "20  libsystem_pthread.dylib             0x00007ff81961718b _pthread_start + 99\n",
      "21  libsystem_pthread.dylib             0x00007ff819612ae3 thread_start + 15\n",
      "\n",
      "Scraping reviews for Banfi Mandrielle Sangiovese\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Mandrielle Sangiovese\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 6 review elements\n",
      "6 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 34 review elements\n",
      "Found 34 review elements\n",
      "34 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 17 review elements\n",
      "Found 17 review elements\n",
      "17 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "1 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 68\n",
      "Scraping reviews for Piccolo Banfi Conclave Reserva Malbec\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Piccolo Banfi Conclave Reserva Malbec\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 20 review elements\n",
      "Found 20 review elements\n",
      "20 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 60 review elements\n",
      "Found 70 review elements\n",
      "Found 80 review elements\n",
      "Found 90 review elements\n",
      "Found 100 review elements\n",
      "Found 101 review elements\n",
      "Found 101 review elements\n",
      "101 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 4 review elements\n",
      "4 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 4 review elements\n",
      "4 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 139\n",
      "Scraping reviews for Banfi Artigiano Chianti Classico\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Artigiano Chianti Classico\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 2 review elements\n",
      "2 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 12 review elements\n",
      "Found 12 review elements\n",
      "12 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 18 review elements\n",
      "Found 18 review elements\n",
      "18 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 4 review elements\n",
      "4 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "1 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 37\n",
      "Scraping reviews for Banfi Santa Costanza Novello\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Santa Costanza Novello\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 11 review elements\n",
      "Found 11 review elements\n",
      "11 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 35 review elements\n",
      "Found 35 review elements\n",
      "35 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 51 review elements\n",
      "Found 51 review elements\n",
      "51 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 8 review elements\n",
      "8 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 115\n",
      "Scraping reviews for Piccolo Banfi Conclave Gran Corte\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Piccolo Banfi Conclave Gran Corte\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 20 review elements\n",
      "Found 22 review elements\n",
      "Found 22 review elements\n",
      "22 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 60 review elements\n",
      "Found 70 review elements\n",
      "Found 80 review elements\n",
      "Found 90 review elements\n",
      "Found 100 review elements\n",
      "Found 110 review elements\n",
      "Found 120 review elements\n",
      "Found 130 review elements\n",
      "Found 140 review elements\n",
      "Found 150 review elements\n",
      "Found 160 review elements\n",
      "Found 169 review elements\n",
      "Found 169 review elements\n",
      "169 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 5 review elements\n",
      "5 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "Error in extracting review details: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"div/div[1]/div[1]/a/span[1]\"}\n",
      "  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001050b40e8 chromedriver + 5169384\n",
      "1   chromedriver                        0x00000001050abfba chromedriver + 5136314\n",
      "2   chromedriver                        0x0000000104c2836c chromedriver + 402284\n",
      "3   chromedriver                        0x0000000104c75740 chromedriver + 718656\n",
      "4   chromedriver                        0x0000000104c75a01 chromedriver + 719361\n",
      "5   chromedriver                        0x0000000104c69ff6 chromedriver + 671734\n",
      "6   chromedriver                        0x0000000104c98add chromedriver + 862941\n",
      "7   chromedriver                        0x0000000104c69ed8 chromedriver + 671448\n",
      "8   chromedriver                        0x0000000104c98c6e chromedriver + 863342\n",
      "9   chromedriver                        0x0000000104cb7f57 chromedriver + 991063\n",
      "10  chromedriver                        0x0000000104c98853 chromedriver + 862291\n",
      "11  chromedriver                        0x0000000104c685c6 chromedriver + 665030\n",
      "12  chromedriver                        0x0000000104c68e4e chromedriver + 667214\n",
      "13  chromedriver                        0x0000000105076d00 chromedriver + 4918528\n",
      "14  chromedriver                        0x000000010507bcfd chromedriver + 4939005\n",
      "15  chromedriver                        0x000000010507c3d5 chromedriver + 4940757\n",
      "16  chromedriver                        0x0000000105057de4 chromedriver + 4791780\n",
      "17  chromedriver                        0x000000010507c6c9 chromedriver + 4941513\n",
      "18  chromedriver                        0x00000001050495b4 chromedriver + 4732340\n",
      "19  chromedriver                        0x000000010509c898 chromedriver + 5073048\n",
      "20  chromedriver                        0x000000010509ca57 chromedriver + 5073495\n",
      "21  chromedriver                        0x00000001050abb6e chromedriver + 5135214\n",
      "22  libsystem_pthread.dylib             0x00007ff81961718b _pthread_start + 99\n",
      "23  libsystem_pthread.dylib             0x00007ff819612ae3 thread_start + 15\n",
      "\n",
      "0 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 206\n",
      "Scraping reviews for Banfi Evoluzione\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Evoluzione\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 7 review elements\n",
      "7 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 45 review elements\n",
      "Found 45 review elements\n",
      "45 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 7 review elements\n",
      "7 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "Error in extracting review details: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"div/div[1]/div[1]/a/span[1]\"}\n",
      "  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001050b40e8 chromedriver + 5169384\n",
      "1   chromedriver                        0x00000001050abfba chromedriver + 5136314\n",
      "2   chromedriver                        0x0000000104c2836c chromedriver + 402284\n",
      "3   chromedriver                        0x0000000104c75740 chromedriver + 718656\n",
      "4   chromedriver                        0x0000000104c75a01 chromedriver + 719361\n",
      "5   chromedriver                        0x0000000104c69ff6 chromedriver + 671734\n",
      "6   chromedriver                        0x0000000104c98add chromedriver + 862941\n",
      "7   chromedriver                        0x0000000104c69ed8 chromedriver + 671448\n",
      "8   chromedriver                        0x0000000104c98c6e chromedriver + 863342\n",
      "9   chromedriver                        0x0000000104cb7f57 chromedriver + 991063\n",
      "10  chromedriver                        0x0000000104c98853 chromedriver + 862291\n",
      "11  chromedriver                        0x0000000104c685c6 chromedriver + 665030\n",
      "12  chromedriver                        0x0000000104c68e4e chromedriver + 667214\n",
      "13  chromedriver                        0x0000000105076d00 chromedriver + 4918528\n",
      "14  chromedriver                        0x000000010507bcfd chromedriver + 4939005\n",
      "15  chromedriver                        0x000000010507c3d5 chromedriver + 4940757\n",
      "16  chromedriver                        0x0000000105057de4 chromedriver + 4791780\n",
      "17  chromedriver                        0x000000010507c6c9 chromedriver + 4941513\n",
      "18  chromedriver                        0x00000001050495b4 chromedriver + 4732340\n",
      "19  chromedriver                        0x000000010509c898 chromedriver + 5073048\n",
      "20  chromedriver                        0x000000010509ca57 chromedriver + 5073495\n",
      "21  chromedriver                        0x00000001050abb6e chromedriver + 5135214\n",
      "22  libsystem_pthread.dylib             0x00007ff81961718b _pthread_start + 99\n",
      "23  libsystem_pthread.dylib             0x00007ff819612ae3 thread_start + 15\n",
      "\n",
      "0 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 69\n",
      "Scraping reviews for Banfi Sangiovese Toscana\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Sangiovese Toscana\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 18 review elements\n",
      "Found 18 review elements\n",
      "18 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 34 review elements\n",
      "Found 34 review elements\n",
      "34 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 3 review elements\n",
      "3 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 3 review elements\n",
      "3 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 68\n",
      "Scraping reviews for Banfi Sciandor Brachetto d'Acqui\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Sciandor Brachetto d'Acqui\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 4 review elements\n",
      "4 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 15 review elements\n",
      "Found 15 review elements\n",
      "15 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 3 review elements\n",
      "3 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "1 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 33\n",
      "Scraping reviews for Banfi Traversa dei Monti Chianti Colli Senesi\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Traversa dei Monti Chianti Colli Senesi\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 4 review elements\n",
      "4 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 11 review elements\n",
      "Found 11 review elements\n",
      "11 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 1 review elements\n",
      "1 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "1 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 27\n",
      "Scraping reviews for Banfi Vigna Marrucheto Brunello di Montalcino\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Vigna Marrucheto Brunello di Montalcino\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 9 review elements\n",
      "9 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 40 review elements\n",
      "Found 50 review elements\n",
      "Found 60 review elements\n",
      "Found 70 review elements\n",
      "Found 80 review elements\n",
      "Found 90 review elements\n",
      "Found 90 review elements\n",
      "90 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 7 review elements\n",
      "7 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 2 review elements\n",
      "2 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "Error in extracting review details: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"div/div[1]/div[1]/a/span[1]\"}\n",
      "  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001050b40e8 chromedriver + 5169384\n",
      "1   chromedriver                        0x00000001050abfba chromedriver + 5136314\n",
      "2   chromedriver                        0x0000000104c2836c chromedriver + 402284\n",
      "3   chromedriver                        0x0000000104c75740 chromedriver + 718656\n",
      "4   chromedriver                        0x0000000104c75a01 chromedriver + 719361\n",
      "5   chromedriver                        0x0000000104c69ff6 chromedriver + 671734\n",
      "6   chromedriver                        0x0000000104c98add chromedriver + 862941\n",
      "7   chromedriver                        0x0000000104c69ed8 chromedriver + 671448\n",
      "8   chromedriver                        0x0000000104c98c6e chromedriver + 863342\n",
      "9   chromedriver                        0x0000000104cb7f57 chromedriver + 991063\n",
      "10  chromedriver                        0x0000000104c98853 chromedriver + 862291\n",
      "11  chromedriver                        0x0000000104c685c6 chromedriver + 665030\n",
      "12  chromedriver                        0x0000000104c68e4e chromedriver + 667214\n",
      "13  chromedriver                        0x0000000105076d00 chromedriver + 4918528\n",
      "14  chromedriver                        0x000000010507bcfd chromedriver + 4939005\n",
      "15  chromedriver                        0x000000010507c3d5 chromedriver + 4940757\n",
      "16  chromedriver                        0x0000000105057de4 chromedriver + 4791780\n",
      "17  chromedriver                        0x000000010507c6c9 chromedriver + 4941513\n",
      "18  chromedriver                        0x00000001050495b4 chromedriver + 4732340\n",
      "19  chromedriver                        0x000000010509c898 chromedriver + 5073048\n",
      "20  chromedriver                        0x000000010509ca57 chromedriver + 5073495\n",
      "21  chromedriver                        0x00000001050abb6e chromedriver + 5135214\n",
      "22  libsystem_pthread.dylib             0x00007ff81961718b _pthread_start + 99\n",
      "23  libsystem_pthread.dylib             0x00007ff819612ae3 thread_start + 15\n",
      "\n",
      "0 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 108\n",
      "Scraping reviews for Banfi Tavernelle Cabernet Sauvignon\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Tavernelle Cabernet Sauvignon\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 16 review elements\n",
      "Found 16 review elements\n",
      "16 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 20 review elements\n",
      "Found 30 review elements\n",
      "Found 37 review elements\n",
      "Found 37 review elements\n",
      "37 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 1 review elements\n",
      "Error in extracting review details: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"div/div[1]/div[1]/a/span[1]\"}\n",
      "  (Session info: chrome=126.0.6478.127); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001050b40e8 chromedriver + 5169384\n",
      "1   chromedriver                        0x00000001050abfba chromedriver + 5136314\n",
      "2   chromedriver                        0x0000000104c2836c chromedriver + 402284\n",
      "3   chromedriver                        0x0000000104c75740 chromedriver + 718656\n",
      "4   chromedriver                        0x0000000104c75a01 chromedriver + 719361\n",
      "5   chromedriver                        0x0000000104c69ff6 chromedriver + 671734\n",
      "6   chromedriver                        0x0000000104c98add chromedriver + 862941\n",
      "7   chromedriver                        0x0000000104c69ed8 chromedriver + 671448\n",
      "8   chromedriver                        0x0000000104c98c6e chromedriver + 863342\n",
      "9   chromedriver                        0x0000000104cb7f57 chromedriver + 991063\n",
      "10  chromedriver                        0x0000000104c98853 chromedriver + 862291\n",
      "11  chromedriver                        0x0000000104c685c6 chromedriver + 665030\n",
      "12  chromedriver                        0x0000000104c68e4e chromedriver + 667214\n",
      "13  chromedriver                        0x0000000105076d00 chromedriver + 4918528\n",
      "14  chromedriver                        0x000000010507bcfd chromedriver + 4939005\n",
      "15  chromedriver                        0x000000010507c3d5 chromedriver + 4940757\n",
      "16  chromedriver                        0x0000000105057de4 chromedriver + 4791780\n",
      "17  chromedriver                        0x000000010507c6c9 chromedriver + 4941513\n",
      "18  chromedriver                        0x00000001050495b4 chromedriver + 4732340\n",
      "19  chromedriver                        0x000000010509c898 chromedriver + 5073048\n",
      "20  chromedriver                        0x000000010509ca57 chromedriver + 5073495\n",
      "21  chromedriver                        0x00000001050abb6e chromedriver + 5135214\n",
      "22  libsystem_pthread.dylib             0x00007ff81961718b _pthread_start + 99\n",
      "23  libsystem_pthread.dylib             0x00007ff819612ae3 thread_start + 15\n",
      "\n",
      "0 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "1 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 64\n",
      "Scraping reviews for Banfi Vigne Regali Asti Dolce\n",
      "Error in extracting price: 'NoneType' object has no attribute 'text'\n",
      "Scraping reviews for Banfi Vigne Regali Asti Dolce\n",
      "Scraping 5-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]...\n",
      "Found 20 review elements\n",
      "Found 21 review elements\n",
      "Found 21 review elements\n",
      "21 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]-star rating.\n",
      "Scraping 4-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]-star rating.\n",
      "Scraping 3-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]...\n",
      "Found 10 review elements\n",
      "10 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]-star rating.\n",
      "Scraping 2-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]...\n",
      "Found 2 review elements\n",
      "2 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]-star rating.\n",
      "Scraping 1-star reviews...\n",
      "Clicking on the star rating with XPath: //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]...\n",
      "Found 1 review elements\n",
      "1 reviews scraped for //*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]-star rating.\n",
      "Total reviews scraped: 44\n",
      "Next page button found, terminating the script.\n",
      "DataFrames saved as CSV and JSON files.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def init_driver():\n",
    "    print(\"Initializing the Chrome driver...\")\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page_and_agree(driver, base_url):\n",
    "    print(f\"Navigating to {base_url}...\")\n",
    "    driver.get(base_url)\n",
    "    time.sleep(10)  # Increase the wait time if needed\n",
    "\n",
    "    try:\n",
    "        print(\"Looking for the 'Agree and Close' button...\")\n",
    "        agree_button = driver.find_element(By.XPATH, '//*[@id=\"didomi-notice-agree-button\"]/span')\n",
    "        agree_button.click()\n",
    "        print(\"'Agree and Close' button clicked.\")\n",
    "        time.sleep(10)  # Increase the wait time if needed\n",
    "    except Exception as e:\n",
    "        print(\"No 'Agree and Close' button found or error in clicking:\", e)\n",
    "\n",
    "def scrape_reviews(driver, star_xpath, max_reviews=200):\n",
    "    try:\n",
    "        print(f\"Clicking on the star rating with XPath: {star_xpath}...\")\n",
    "        star_button = driver.find_element(By.XPATH, star_xpath)\n",
    "        star_button.click()\n",
    "        time.sleep(10)  # Increase the wait time if needed\n",
    "\n",
    "        reviews = []\n",
    "        unique_commenters = set()\n",
    "        scrollable_popup = driver.find_element(By.XPATH, '//*[@id=\"baseModal\"]/div/div[2]')\n",
    "\n",
    "        last_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_popup)\n",
    "        new_reviews_found = True\n",
    "\n",
    "        while new_reviews_found and len(reviews) < max_reviews:\n",
    "            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollable_popup)\n",
    "            time.sleep(5)  # Increase the wait time if needed\n",
    "\n",
    "            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_popup)\n",
    "            new_reviews_found = new_height != last_height\n",
    "            last_height = new_height\n",
    "\n",
    "            review_elements = driver.find_elements(By.XPATH, '//*[@id=\"baseModal\"]/div/div[2]/div[3]/div')\n",
    "            print(f\"Found {len(review_elements)} review elements\")\n",
    "            for review_element in review_elements[len(reviews):]:\n",
    "                if len(reviews) >= max_reviews:\n",
    "                    break\n",
    "                try:\n",
    "                    rating = review_element.find_element(By.XPATH, 'div/div[1]/div[1]/a/span[1]').text.strip()\n",
    "\n",
    "                    spans = review_element.find_elements(By.XPATH, 'div/div[1]/div[1]/a/span')\n",
    "                    if len(spans) == 3:\n",
    "                        review_text = spans[2].text.strip()\n",
    "                    else:\n",
    "                        review_text = spans[1].text.strip()\n",
    "\n",
    "                    commenter_name = review_element.find_element(By.XPATH, 'div/div[1]/div[2]/div[1]/div/a[1]').text.strip()\n",
    "                    review_date = review_element.find_element(By.XPATH, 'div/div[1]/div[2]/div[1]/div/a[2]').text.strip()\n",
    "\n",
    "                    if commenter_name not in unique_commenters:\n",
    "                        reviews.append({\n",
    "                            'Rating': rating,\n",
    "                            'Review Text': review_text,\n",
    "                            'Commenter Name': commenter_name,\n",
    "                            'Review Date': review_date\n",
    "                        })\n",
    "                        unique_commenters.add(commenter_name)\n",
    "                except Exception as e:\n",
    "                    print(\"Error in extracting review details:\", e)\n",
    "\n",
    "        print(f\"{len(reviews)} reviews scraped for {star_xpath.split()[-1]}-star rating.\")\n",
    "\n",
    "        # Unclick the star rating\n",
    "        star_button.click()\n",
    "        time.sleep(3)  # Wait for the action to be processed\n",
    "\n",
    "        return reviews\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error in scraping reviews for star rating:\", e)\n",
    "        return []\n",
    "\n",
    "def scrape_wine_reviews(driver, wine_url, wine_name):\n",
    "    driver.get(wine_url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    print(f\"Scraping reviews for {wine_name}\")\n",
    "\n",
    "    try:\n",
    "        average_rating_link = driver.find_element(By.XPATH, '//*[@id=\"wine-location-header\"]/div/div/div/div[2]/a')\n",
    "        average_rating_link.click()\n",
    "        time.sleep(10)\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight * 0.7);\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        show_more_reviews_button = driver.find_element(By.XPATH, '//*[@id=\"all_reviews\"]/div[2]/div[1]/button/span')\n",
    "        show_more_reviews_button.click()\n",
    "        time.sleep(10)\n",
    "\n",
    "        star_xpaths = {\n",
    "            '5': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[1]',\n",
    "            '4': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[2]',\n",
    "            '3': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[3]',\n",
    "            '2': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[4]',\n",
    "            '1': '//*[@id=\"baseModal\"]/div/div[2]/div[2]/div[1]/div/div/div[5]'\n",
    "        }\n",
    "\n",
    "        all_reviews = []\n",
    "        for star, xpath in star_xpaths.items():\n",
    "            print(f\"Scraping {star}-star reviews...\")\n",
    "            reviews = scrape_reviews(driver, xpath)\n",
    "            all_reviews.extend(reviews)\n",
    "\n",
    "        print(f\"Total reviews scraped: {len(all_reviews)}\")\n",
    "\n",
    "        return all_reviews\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in scraping reviews for {wine_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_banfi_wines(driver, base_url):\n",
    "    all_wine_details = []\n",
    "    all_reviews = []\n",
    "    scraped_wines = set()\n",
    "    driver.get(base_url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    try:\n",
    "        agree_button = driver.find_element(By.XPATH, '//*[@id=\"didomi-notice-agree-button\"]')\n",
    "        agree_button.click()\n",
    "        time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(\"No 'Agree and Continue' button found or error in clicking:\", e)\n",
    "\n",
    "    print(\"Scraping wines on the current page\")\n",
    "\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(10)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    wines = soup.find_all('div', class_='card card-lg')\n",
    "\n",
    "    for wine in wines:\n",
    "        try:\n",
    "            wine_name = wine.find('a', class_='link-color-alt-grey').text.strip()\n",
    "            if \"Banfi\" in wine_name and wine_name not in scraped_wines:\n",
    "                wine_link = wine.find('a', class_='link-color-alt-grey')['href']\n",
    "                wine_url = f\"https://www.vivino.com{wine_link}\"\n",
    "                print(f\"Scraping reviews for {wine_name}\")\n",
    "\n",
    "                wine_details = {\n",
    "                    'Wine Name': wine_name,\n",
    "                    'Brand': 'Banfi',\n",
    "                    'Country': 'Italy'\n",
    "                }\n",
    "\n",
    "                driver.get(wine_url)\n",
    "                time.sleep(10)\n",
    "                soup_wine = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                try:\n",
    "                    wine_price = soup_wine.find('span', class_='wine-price-value').text.strip()\n",
    "                    wine_details['Price'] = wine_price\n",
    "                except Exception as e:\n",
    "                    print(\"Error in extracting price:\", e)\n",
    "\n",
    "                wine_reviews = scrape_wine_reviews(driver, wine_url, wine_name)\n",
    "                all_reviews.extend(wine_reviews)\n",
    "                all_wine_details.append(wine_details)\n",
    "                scraped_wines.add(wine_name)\n",
    "\n",
    "                driver.get(base_url)\n",
    "                time.sleep(10)\n",
    "        except Exception as e:\n",
    "            print(\"Error in processing wine:\", e)\n",
    "\n",
    "    # Check if there is a next page\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '/html/body/div[3]/section[1]/div/div/div/div[2]/button[2]')\n",
    "        print(\"Next page button found, terminating the script.\")\n",
    "    except Exception as e:\n",
    "        print(\"No more pages to load or error in finding next button:\", e)\n",
    "\n",
    "    return all_wine_details, all_reviews\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        driver = init_driver()\n",
    "        base_url = \"https://www.vivino.com/search/wines?q=banfi&start=3\"\n",
    "        all_wine_details, all_reviews = scrape_all_banfi_wines(driver, base_url)\n",
    "        \n",
    "        df_wine_details = pd.DataFrame(all_wine_details)\n",
    "        df_reviews = pd.DataFrame(all_reviews)\n",
    "\n",
    "        df_wine_details.to_csv('banfi_wine_details_page3.csv', index=False)\n",
    "        df_reviews.to_csv('banfi_wine_reviews_page3.csv', index=False)\n",
    "\n",
    "        df_wine_details.to_json('banfi_wine_details_page3.json', orient='records', lines=True)\n",
    "        df_reviews.to_json('banfi_wine_reviews_page3.json', orient='records', lines=True)\n",
    "\n",
    "        print(\"DataFrames saved as CSV and JSON files.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Process interrupted. Saving files...\")\n",
    "\n",
    "        df_wine_details.to_csv('banfi_wine_details_page3.csv', index=False)\n",
    "        df_reviews.to_csv('banfi_wine_reviews_page3.csv', index=False)\n",
    "\n",
    "        df_wine_details.to_json('banfi_wine_details_page3.json', orient='records', lines=True)\n",
    "        df_reviews.to_json('banfi_wine_reviews_page3.json', orient='records', lines=True)\n",
    "\n",
    "        print(\"DataFrames saved as CSV and JSON files.\")\n",
    "        driver.quit()\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING AND CONSOLIDATING DATA INTO ONE CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated data saved to banfi_wine_reviews_consolidated.csv\n",
      "Consolidated data saved to banfi_wine_details_consolidated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV files for reviews and wine details\n",
    "review_files = ['banfi_wine_reviews.csv', 'banfi_wine_reviews_page2.csv', 'banfi_wine_reviews_page3.csv']\n",
    "wine_details_files = ['banfi_wine_details.csv', 'banfi_wine_details_page2.csv', 'banfi_wine_details_page3.csv']\n",
    "\n",
    "# Function to consolidate CSV files and drop empty rows\n",
    "def consolidate_csv(file_list, output_file):\n",
    "    df_list = []\n",
    "    for file in file_list:\n",
    "        df = pd.read_csv(file)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    consolidated_df = pd.concat(df_list, ignore_index=True)\n",
    "    consolidated_df.dropna(how='all', inplace=True)  # Drop rows where all elements are NaN\n",
    "    \n",
    "    consolidated_df.to_csv(output_file, index=False)\n",
    "    print(f\"Consolidated data saved to {output_file}\")\n",
    "\n",
    "# Consolidate reviews\n",
    "consolidate_csv(review_files, 'banfi_wine_reviews_consolidated.csv')\n",
    "\n",
    "# Consolidate wine details\n",
    "consolidate_csv(wine_details_files, 'banfi_wine_details_consolidated.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
